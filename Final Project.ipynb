{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39092fe-0db9-421a-ad5a-4c010e628f29",
   "metadata": {},
   "source": [
    "# Final Project | Cody Laurie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d6e16a-31e1-4842-9b59-830895e62015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DF (budget) shape: (124, 24)\n",
      "CAASPP shape: (4050626, 70)\n",
      "Merged (intersection) shape: (30726, 94)\n",
      "\n",
      "Merged head:\n",
      "                   X                 Y  ID  LOCN   MPD_NAME  \\\n",
      "0  -13157737.0803322  4026937.00783967  75  8268  NIMITZ MS   \n",
      "1  -13157737.0803322  4026937.00783967  75  8268  NIMITZ MS   \n",
      "2  -13157737.0803322  4026937.00783967  75  8268  NIMITZ MS   \n",
      "3  -13157737.0803322  4026937.00783967  75  8268  NIMITZ MS   \n",
      "4  -13157737.0803322  4026937.00783967  75  8268  NIMITZ MS   \n",
      "\n",
      "              ADDRESS             CITY    ZIP MPD_TYPE MAP_TYPE  ...  \\\n",
      "0  6021 CARMELITA AVE  HUNTINGTON PARK  90255        J       MS  ...   \n",
      "1  6021 CARMELITA AVE  HUNTINGTON PARK  90255        J       MS  ...   \n",
      "2  6021 CARMELITA AVE  HUNTINGTON PARK  90255        J       MS  ...   \n",
      "3  6021 CARMELITA AVE  HUNTINGTON PARK  90255        J       MS  ...   \n",
      "4  6021 CARMELITA AVE  HUNTINGTON PARK  90255        J       MS  ...   \n",
      "\n",
      "  Composite Area 1 Count Below Standard Composite Area 1 Total  \\\n",
      "0                                   117                    318   \n",
      "1                                    71                    169   \n",
      "2                                    46                    149   \n",
      "3                                    90                    280   \n",
      "4                                     1                     14   \n",
      "\n",
      "  Composite Area 2 Percentage Above Standard  \\\n",
      "0                                      17.92   \n",
      "1                                      16.57   \n",
      "2                                      19.46   \n",
      "3                                      20.36   \n",
      "4                                      35.71   \n",
      "\n",
      "  Composite Area 2 Count Above Standard  \\\n",
      "0                                    57   \n",
      "1                                    28   \n",
      "2                                    29   \n",
      "3                                    57   \n",
      "4                                     5   \n",
      "\n",
      "  Composite Area 2 Percentage Near Standard  \\\n",
      "0                                     43.71   \n",
      "1                                     37.28   \n",
      "2                                     51.01   \n",
      "3                                     46.07   \n",
      "4                                     57.14   \n",
      "\n",
      "  Composite Area 2 Count Near Standard  \\\n",
      "0                                  139   \n",
      "1                                   63   \n",
      "2                                   76   \n",
      "3                                  129   \n",
      "4                                    8   \n",
      "\n",
      "  Composite Area 2 Percentage Below Standard  \\\n",
      "0                                      38.36   \n",
      "1                                      46.15   \n",
      "2                                      29.53   \n",
      "3                                      33.57   \n",
      "4                                       7.14   \n",
      "\n",
      "  Composite Area 2 Count Below Standard Composite Area 2 Total         CDSCode  \n",
      "0                                   122                    318  19647336057939  \n",
      "1                                    78                    169  19647336057939  \n",
      "2                                    44                    149  19647336057939  \n",
      "3                                    94                    280  19647336057939  \n",
      "4                                     1                     14  19647336057939  \n",
      "\n",
      "[5 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CAASPP dataset caret-delimited \"^\" with latin1 encoding\n",
    "caaspp = pd.read_csv(\n",
    "    \"sb_ca2024_all_csv_v1.txt\",\n",
    "    delimiter=\"^\",\n",
    "    encoding=\"latin1\",   # fixes UnicodeDecodeError\n",
    "    dtype={\n",
    "        \"County Code\": str,\n",
    "        \"District Code\": str,\n",
    "        \"School Code\": str\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create CDSCode (County + District + School) → 14-digit string\n",
    "caaspp[\"CDSCode\"] = (\n",
    "    caaspp[\"County Code\"].str.zfill(2) +\n",
    "    caaspp[\"District Code\"].str.zfill(5) +\n",
    "    caaspp[\"School Code\"].str.zfill(7)\n",
    ")\n",
    "\n",
    "# Load DF dataset (budget/expenditure, your pasted table)\n",
    "df = pd.read_csv(\n",
    "    \"df_3_4_inner.csv\",\n",
    "    dtype=str   # keep codes as strings (CDSCODE, etc.)\n",
    ")\n",
    "\n",
    "# Drop unnamed index column if it exists\n",
    "df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\")]\n",
    "\n",
    "# Make sure CDSCODE is a 14-digit string to match CAASPP CDSCode\n",
    "if \"CDSCODE\" in df.columns:\n",
    "    df[\"CDSCODE\"] = df[\"CDSCODE\"].str.zfill(14)\n",
    "else:\n",
    "    raise KeyError(\"Expected column 'CDSCODE' not found in df_3_4_inner.csv\")\n",
    "\n",
    "# Create the 3rd dataset: intersection of schools (inner join)\n",
    "\n",
    "merged = df.merge(\n",
    "    caaspp,\n",
    "    left_on=\"CDSCODE\",\n",
    "    right_on=\"CDSCode\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_budget\", \"_caaspp\")\n",
    ")\n",
    "\n",
    "# 4. Quick sanity checks\n",
    "print(\"Original DF (budget) shape:\", df.shape)\n",
    "print(\"CAASPP shape:\", caaspp.shape)\n",
    "print(\"Merged (intersection) shape:\", merged.shape)\n",
    "\n",
    "print(\"\\nMerged head:\")\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a224c894-9585-4a25-9509-e42a1093b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CAASPP rows (All Students + ELA): (354, 94)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDSCODE</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Student Group ID</th>\n",
       "      <th>Test ID</th>\n",
       "      <th>Mean Scale Score</th>\n",
       "      <th>Percentage Standard Met and Above</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19647336057939</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2500.9</td>\n",
       "      <td>41.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>19647336057939</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2498.9</td>\n",
       "      <td>33.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>19647336057939</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2498.7</td>\n",
       "      <td>29.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>19647336057939</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>19647336061394</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2463.8</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CDSCODE  Grade  Student Group ID  Test ID Mean Scale Score  \\\n",
       "0    19647336057939      6                 1        1           2500.9   \n",
       "39   19647336057939      7                 1        1           2498.9   \n",
       "75   19647336057939      8                 1        1           2498.7   \n",
       "119  19647336057939     13                 1        1              NaN   \n",
       "326  19647336061394      6                 1        1           2463.8   \n",
       "\n",
       "    Percentage Standard Met and Above  \n",
       "0                               41.19  \n",
       "39                              33.24  \n",
       "75                              29.71  \n",
       "119                             34.49  \n",
       "326                             29.93  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter merged CAASPP rows: All Students + ELA\n",
    "# Student Group ID = 1 -> All Students\n",
    "# Test ID = 1 -> ELA\n",
    "\n",
    "filtered = merged[\n",
    "    (merged[\"Student Group ID\"] == 1) &\n",
    "    (merged[\"Test ID\"] == 1)\n",
    "].copy()\n",
    "\n",
    "print(\"Filtered CAASPP rows (All Students + ELA):\", filtered.shape)\n",
    "filtered[[\n",
    "    \"CDSCODE\",\n",
    "    \"Grade\",\n",
    "    \"Student Group ID\",\n",
    "    \"Test ID\",\n",
    "    \"Mean Scale Score\",\n",
    "    \"Percentage Standard Met and Above\"\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526a2922-9fbf-4e95-8bc4-8bbd3705415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example raw values in 'Percentage Standard Met and Above':\n",
      "['41.19', '33.24', '29.71', '34.49', '29.93', '32.03', '19.74', '26.93', '41.67', '57.14', '33.33', '41.86', '52.63', '43.59', '45.61', '30.09', '26.32', '51.52', '38.00', '24.00']\n",
      "\n",
      "Values that contain '*' or other non-numeric characters:\n",
      "5410      *\n",
      "5431      *\n",
      "5458      *\n",
      "6743      *\n",
      "6769      *\n",
      "8882    NaN\n",
      "8896    NaN\n",
      "Name: Percentage Standard Met and Above, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect the raw values in the problematic column\n",
    "\n",
    "print(\"Example raw values in 'Percentage Standard Met and Above':\")\n",
    "print(filtered[\"Percentage Standard Met and Above\"].head(20).tolist())\n",
    "\n",
    "# Detect any values that contain characters other than digits, dot, or minus\n",
    "weird_mask = filtered[\"Percentage Standard Met and Above\"].astype(str).str.contains(\n",
    "    r\"[^0-9.\\-]\", regex=True\n",
    ")\n",
    "\n",
    "print(\"\\nValues that contain '*' or other non-numeric characters:\")\n",
    "print(filtered.loc[weird_mask, \"Percentage Standard Met and Above\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5bf442f-f739-43b2-9ab1-4a5b9fa86b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Standard Met and Above    float64\n",
      "Mean Scale Score                     float64\n",
      "dtype: object\n",
      "\n",
      "Summary after conversion:\n",
      "       Percentage Standard Met and Above  Mean Scale Score\n",
      "count                         347.000000        261.000000\n",
      "mean                           37.625677       2501.986973\n",
      "std                            15.380784         51.268179\n",
      "min                             9.260000       2348.800000\n",
      "25%                            26.100000       2469.500000\n",
      "50%                            34.490000       2495.800000\n",
      "75%                            46.265000       2531.600000\n",
      "max                            85.900000       2666.400000\n"
     ]
    }
   ],
   "source": [
    "# Convert score columns to numeric, invalid entries -> NaN\n",
    "\n",
    "cols_to_convert = [\"Percentage Standard Met and Above\", \"Mean Scale Score\"]\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    filtered[col] = pd.to_numeric(filtered[col], errors=\"coerce\")\n",
    "\n",
    "print(filtered[cols_to_convert].dtypes)\n",
    "\n",
    "print(\"\\nSummary after conversion:\")\n",
    "print(filtered[cols_to_convert].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cc3cdc-4fa7-444d-a075-680ef059318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School-level performance shape: (87, 3)\n",
      "          CDSCODE  Pct_Met_Above   Mean_Score\n",
      "0  19647330101618        51.9250  2417.200000\n",
      "1  19647330102913        85.9000  2666.400000\n",
      "2  19647330106971        29.2875  2482.233333\n",
      "3  19647330106989        30.5125  2496.766667\n",
      "4  19647330112011        26.2700  2476.100000\n"
     ]
    }
   ],
   "source": [
    "# Aggregate to one performance row per school (CDSCODE)\n",
    "\n",
    "school_perf = filtered.groupby(\"CDSCODE\", as_index=False).agg({\n",
    "    \"Percentage Standard Met and Above\": \"mean\",\n",
    "    \"Mean Scale Score\": \"mean\"\n",
    "})\n",
    "\n",
    "school_perf.rename(columns={\n",
    "    \"Percentage Standard Met and Above\": \"Pct_Met_Above\",\n",
    "    \"Mean Scale Score\": \"Mean_Score\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"School-level performance shape:\", school_perf.shape)\n",
    "print(school_perf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1cbfb06-0454-4d02-be38-7c8bc4520b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final modeling dataset shape (funding + scores): (87, 26)\n",
      "                MPD_NAME         CDSCODE Budget (incl c/o) FY24  \\\n",
      "0              NIMITZ MS  19647336057939             18802827.0   \n",
      "1             AUDUBON MS  19647336061394             12618220.0   \n",
      "2  WESTSIDE GLBL AWR MAG  19647331931054              5263785.0   \n",
      "3            PIO PICO MS  19647336107064              6573638.0   \n",
      "4           BELVEDERE MS  19647336057889             13920639.0   \n",
      "\n",
      "    Expenditures FY24          % Exp FY24  Pct_Met_Above   Mean_Score  \n",
      "0  16689938.429999998  0.8876292075654367      34.657500  2499.500000  \n",
      "1  10690015.330000024   0.847188853102896      27.157500  2473.133333  \n",
      "2   4628859.740000002    0.87937857264307      45.118571  2482.016667  \n",
      "3   4915339.489999995  0.7477350426050224      36.482500  2503.633333  \n",
      "4  11795271.360000052  0.8473225517880358      30.900000  2491.900000  \n"
     ]
    }
   ],
   "source": [
    "# Merge performance back with the budget/expenditure DF\n",
    "\n",
    "final = df.merge(school_perf, on=\"CDSCODE\", how=\"inner\")\n",
    "\n",
    "print(\"\\nFinal modeling dataset shape (funding + scores):\", final.shape)\n",
    "print(final[[\n",
    "    \"MPD_NAME\", \"CDSCODE\",\n",
    "    \"Budget (incl c/o) FY24\", \"Expenditures FY24\", \"% Exp FY24\",\n",
    "    \"Pct_Met_Above\", \"Mean_Score\"\n",
    "]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bee5c52-4322-41e0-bbb4-b2a890d165dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After numeric conversion and dropna: (86, 26)\n",
      "\n",
      "Correlation matrix (funding vs scores):\n",
      "                        Budget (incl c/o) FY24  Expenditures FY24  % Exp FY24  \\\n",
      "Budget (incl c/o) FY24                1.000000           0.982787    0.091530   \n",
      "Expenditures FY24                     0.982787           1.000000    0.261613   \n",
      "% Exp FY24                            0.091530           0.261613    1.000000   \n",
      "Pct_Met_Above                         0.128015           0.187554    0.297107   \n",
      "Mean_Score                            0.214331           0.274633    0.342998   \n",
      "\n",
      "                        Pct_Met_Above  Mean_Score  \n",
      "Budget (incl c/o) FY24       0.128015    0.214331  \n",
      "Expenditures FY24            0.187554    0.274633  \n",
      "% Exp FY24                   0.297107    0.342998  \n",
      "Pct_Met_Above                1.000000    0.830659  \n",
      "Mean_Score                   0.830659    1.000000  \n",
      "\n",
      "Median Expenditures FY24: 12103303.374999985\n",
      "\n",
      "Average % Met & Above by Funding Level:\n",
      "Funding_Level\n",
      "High    42.018878\n",
      "Low     32.388873\n",
      "Name: Pct_Met_Above, dtype: float64\n",
      "\n",
      "Lift (High funding vs Low funding) on % Met & Above:\n",
      "Lift = 1.297324474579192\n"
     ]
    }
   ],
   "source": [
    "# Convert numeric columns to proper dtypes\n",
    "\n",
    "numeric_cols = [\n",
    "    \"Budget (incl c/o) FY24\",\n",
    "    \"Expenditures FY24\",\n",
    "    \"% Exp FY24\",\n",
    "    \"Pct_Met_Above\",\n",
    "    \"Mean_Score\"\n",
    "]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    final[col] = pd.to_numeric(final[col], errors=\"coerce\")\n",
    "\n",
    "final_clean = final.dropna(subset=numeric_cols).copy()\n",
    "print(\"After numeric conversion and dropna:\", final_clean.shape)\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = final_clean[numeric_cols].corr()\n",
    "print(\"\\nCorrelation matrix (funding vs scores):\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Lift between high-funded and low-funded schools\n",
    "import numpy as np\n",
    "\n",
    "median_exp = final_clean[\"Expenditures FY24\"].median()\n",
    "print(\"\\nMedian Expenditures FY24:\", median_exp)\n",
    "\n",
    "final_clean[\"Funding_Level\"] = np.where(\n",
    "    final_clean[\"Expenditures FY24\"] >= median_exp,\n",
    "    \"High\",\n",
    "    \"Low\"\n",
    ")\n",
    "\n",
    "lift_table = final_clean.groupby(\"Funding_Level\")[\"Pct_Met_Above\"].mean()\n",
    "high_mean = lift_table.get(\"High\", np.nan)\n",
    "low_mean = lift_table.get(\"Low\", np.nan)\n",
    "lift_value = high_mean / low_mean if (low_mean not in [0, np.nan]) else np.nan\n",
    "\n",
    "print(\"\\nAverage % Met & Above by Funding Level:\")\n",
    "print(lift_table)\n",
    "\n",
    "print(\"\\nLift (High funding vs Low funding) on % Met & Above:\")\n",
    "print(\"Lift =\", lift_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633109a4-6fd2-4505-806f-a987539e140b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'ID', 'LOCN', 'MPD_NAME', 'ADDRESS', 'CITY', 'ZIP',\n",
       "       'MPD_TYPE', 'MAP_TYPE', 'LABEL', 'MAP_DESC', 'MPD_DESC', 'LD',\n",
       "       'FULLNAME', 'CDSCODE', 'CHARTER', 'MAP_TYPE_MAPPING', 'TOOLTIP',\n",
       "       'NLA_URL', 'Campus', 'Budget (incl c/o) FY24', 'Expenditures FY24',\n",
       "       '% Exp FY24', 'Pct_Met_Above', 'Mean_Score', 'Funding_Level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296e62ab-909f-4b39-aa2f-97a450984f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (86, 107)\n",
      "y distribution:\n",
      " Pct_Met_Above\n",
      "1    43\n",
      "0    43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preview of X:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Budget (incl c/o) FY24</th>\n",
       "      <th>Expenditures FY24</th>\n",
       "      <th>% Exp FY24</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MPD_TYPE_CDS</th>\n",
       "      <th>MPD_TYPE_E</th>\n",
       "      <th>MPD_TYPE_EJ</th>\n",
       "      <th>MPD_TYPE_EP</th>\n",
       "      <th>MPD_TYPE_ES</th>\n",
       "      <th>MPD_TYPE_J</th>\n",
       "      <th>...</th>\n",
       "      <th>Campus_VAN NUYS MS</th>\n",
       "      <th>Campus_VIRGIL MS</th>\n",
       "      <th>Campus_VISTA MS</th>\n",
       "      <th>Campus_WEBSTER MS</th>\n",
       "      <th>Campus_WESM HLTH/SPORTS MED</th>\n",
       "      <th>Campus_WESTSIDE GLBL AWR MAG</th>\n",
       "      <th>Campus_WHITE MS</th>\n",
       "      <th>Campus_WOODLAND HILLS ACAD</th>\n",
       "      <th>Campus_WRIGHT ENG DES MAG</th>\n",
       "      <th>Campus_YES ACADEMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18802827.0</td>\n",
       "      <td>16689938.43</td>\n",
       "      <td>0.887629</td>\n",
       "      <td>90255</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12618220.0</td>\n",
       "      <td>10690015.33</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>90008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5263785.0</td>\n",
       "      <td>4628859.74</td>\n",
       "      <td>0.879379</td>\n",
       "      <td>90292</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6573638.0</td>\n",
       "      <td>4915339.49</td>\n",
       "      <td>0.747735</td>\n",
       "      <td>90019</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13920639.0</td>\n",
       "      <td>11795271.36</td>\n",
       "      <td>0.847323</td>\n",
       "      <td>90063</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Budget (incl c/o) FY24  Expenditures FY24  % Exp FY24    ZIP  MPD_TYPE_CDS  \\\n",
       "0              18802827.0        16689938.43    0.887629  90255         False   \n",
       "1              12618220.0        10690015.33    0.847189  90008         False   \n",
       "2               5263785.0         4628859.74    0.879379  90292         False   \n",
       "3               6573638.0         4915339.49    0.747735  90019         False   \n",
       "4              13920639.0        11795271.36    0.847323  90063         False   \n",
       "\n",
       "   MPD_TYPE_E  MPD_TYPE_EJ  MPD_TYPE_EP  MPD_TYPE_ES  MPD_TYPE_J  ...  \\\n",
       "0       False        False        False        False        True  ...   \n",
       "1       False        False        False        False        True  ...   \n",
       "2       False        False        False        False       False  ...   \n",
       "3       False        False        False        False        True  ...   \n",
       "4       False        False        False        False        True  ...   \n",
       "\n",
       "   Campus_VAN NUYS MS  Campus_VIRGIL MS  Campus_VISTA MS  Campus_WEBSTER MS  \\\n",
       "0               False             False            False              False   \n",
       "1               False             False            False              False   \n",
       "2               False             False            False              False   \n",
       "3               False             False            False              False   \n",
       "4               False             False            False              False   \n",
       "\n",
       "   Campus_WESM HLTH/SPORTS MED  Campus_WESTSIDE GLBL AWR MAG  Campus_WHITE MS  \\\n",
       "0                        False                         False            False   \n",
       "1                        False                         False            False   \n",
       "2                        False                          True            False   \n",
       "3                        False                         False            False   \n",
       "4                        False                         False            False   \n",
       "\n",
       "   Campus_WOODLAND HILLS ACAD  Campus_WRIGHT ENG DES MAG  Campus_YES ACADEMY  \n",
       "0                       False                      False               False  \n",
       "1                       False                      False               False  \n",
       "2                       False                      False               False  \n",
       "3                       False                      False               False  \n",
       "4                       False                      False               False  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select approved features\n",
    "\n",
    "numeric_features = [\n",
    "    \"Budget (incl c/o) FY24\",\n",
    "    \"Expenditures FY24\",\n",
    "    \"% Exp FY24\",\n",
    "    \"ZIP\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"MPD_TYPE\",\n",
    "    \"MAP_TYPE\",\n",
    "    \"CHARTER\",\n",
    "    \"LD\",\n",
    "    \"Campus\"\n",
    "]\n",
    "\n",
    "# Extract numeric features as-is\n",
    "X_numeric = final_clean[numeric_features].copy()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_categorical = pd.get_dummies(final_clean[categorical_features], drop_first=True)\n",
    "\n",
    "# Combine numeric + categorical\n",
    "X = pd.concat([X_numeric, X_categorical], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = (final_clean[\"Pct_Met_Above\"] >= final_clean[\"Pct_Met_Above\"].median()).astype(int)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y distribution:\\n\", y.value_counts())\n",
    "print(\"\\nPreview of X:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac15fa0e-d716-49d6-89bc-da59db5ebff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train/test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numeric features for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c1ad4c-0b51-4f6d-b08d-d0f789909bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=500)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc968f1-5b1f-41fe-b82f-125e9994e412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5454545454545454\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.27      0.38        11\n",
      "           1       0.53      0.82      0.64        11\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.56      0.55      0.51        22\n",
      "weighted avg       0.56      0.55      0.51        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80721bec-a748-453f-8d0d-43d693ea64fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>% Exp FY24</td>\n",
       "      <td>0.602833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Campus_PIO PICO MS</td>\n",
       "      <td>0.468021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Campus_KNOLLWOOD PREP ACAD</td>\n",
       "      <td>0.455839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Campus_TORRES RENAISSANCE</td>\n",
       "      <td>0.399977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Campus_MARK TWAIN MS</td>\n",
       "      <td>0.393676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Campus_BURROUGHS MS</td>\n",
       "      <td>0.373664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Campus_PALMS MS</td>\n",
       "      <td>0.340916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Campus_TORRES HUM/ART/TECH</td>\n",
       "      <td>0.340904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Campus_ROYBAL LC</td>\n",
       "      <td>0.333098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Campus_CARNEGIE MS</td>\n",
       "      <td>0.332658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Campus_MULHOLLAND MS</td>\n",
       "      <td>0.320828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Campus_VIRGIL MS</td>\n",
       "      <td>0.313879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Campus_HOLMES MS</td>\n",
       "      <td>0.312840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Campus_REED MS</td>\n",
       "      <td>0.311845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MPD_TYPE_ES</td>\n",
       "      <td>0.300454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature  Coefficient\n",
       "2                   % Exp FY24     0.602833\n",
       "79          Campus_PIO PICO MS     0.468021\n",
       "56  Campus_KNOLLWOOD PREP ACAD     0.455839\n",
       "96   Campus_TORRES RENAISSANCE     0.399977\n",
       "65        Campus_MARK TWAIN MS     0.393676\n",
       "29         Campus_BURROUGHS MS     0.373664\n",
       "77             Campus_PALMS MS     0.340916\n",
       "95  Campus_TORRES HUM/ART/TECH     0.340904\n",
       "85            Campus_ROYBAL LC     0.333098\n",
       "31          Campus_CARNEGIE MS     0.332658\n",
       "71        Campus_MULHOLLAND MS     0.320828\n",
       "98            Campus_VIRGIL MS     0.313879\n",
       "55            Campus_HOLMES MS     0.312840\n",
       "81              Campus_REED MS     0.311845\n",
       "8                  MPD_TYPE_ES     0.300454"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Match coefficients to feature names\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Coefficient\": log_reg.coef_[0]\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "coef_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "187536a5-35e4-49ea-9841-9585c360f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Same split as logistic regression for comparison\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677aa051-dc55-4ef8-ac86-fb5bd51f5eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=300,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=300,\n",
       "                       random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=300,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,        \n",
    "    max_depth=None,         \n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\" \n",
    ")\n",
    "\n",
    "rf.fit(X_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6676fb92-7590-4833-b133-7de0e831e283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7272727272727273\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        11\n",
      "           1       0.73      0.73      0.73        11\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.73      0.73      0.73        22\n",
      "weighted avg       0.73      0.73      0.73        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_rf)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test_rf, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "789a87cc-522b-4665-a3dc-32e624fb5e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>% Exp FY24</td>\n",
       "      <td>0.176537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expenditures FY24</td>\n",
       "      <td>0.151130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget (incl c/o) FY24</td>\n",
       "      <td>0.109244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>0.108791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MPD_TYPE_J</td>\n",
       "      <td>0.022006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Campus_MARK TWAIN MS</td>\n",
       "      <td>0.018513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Campus_OLIVE VISTA MS</td>\n",
       "      <td>0.017340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Campus_SOUTHEAST MS</td>\n",
       "      <td>0.017272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAP_TYPE_MS</td>\n",
       "      <td>0.014630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Campus_PIO PICO MS</td>\n",
       "      <td>0.012550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAP_TYPE_HS</td>\n",
       "      <td>0.012240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MPD_TYPE_ES</td>\n",
       "      <td>0.011215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MPD_TYPE_S</td>\n",
       "      <td>0.010585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Campus_PALMS MS</td>\n",
       "      <td>0.009943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Campus_PEARY MS</td>\n",
       "      <td>0.009420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Importance\n",
       "2               % Exp FY24    0.176537\n",
       "1        Expenditures FY24    0.151130\n",
       "0   Budget (incl c/o) FY24    0.109244\n",
       "3                      ZIP    0.108791\n",
       "9               MPD_TYPE_J    0.022006\n",
       "65    Campus_MARK TWAIN MS    0.018513\n",
       "75   Campus_OLIVE VISTA MS    0.017340\n",
       "91     Campus_SOUTHEAST MS    0.017272\n",
       "18             MAP_TYPE_MS    0.014630\n",
       "79      Campus_PIO PICO MS    0.012550\n",
       "16             MAP_TYPE_HS    0.012240\n",
       "8              MPD_TYPE_ES    0.011215\n",
       "11              MPD_TYPE_S    0.010585\n",
       "77         Campus_PALMS MS    0.009943\n",
       "78         Campus_PEARY MS    0.009420"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6d556a0-fd38-4218-83f9-bc73e856f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Feature'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance_df.head(15).plot(kind='barh', x='Feature', figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec64ee7f-d47d-4f8b-9aa5-005e31070fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (51, 107) Val: (17, 107) Test: (18, 107)\n",
      "\n",
      "=== Standard Random Forest ===\n",
      "Accuracy: 0.6111111111111112\n",
      "Log-loss: 0.6067079595723793\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59         9\n",
      "           1       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.61      0.61      0.61        18\n",
      "weighted avg       0.61      0.61      0.61        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 composite scores: [1.833  3.2178 2.3852 2.21   3.0147]\n",
      "First 5 weights: [0.0027 0.0108 0.0047 0.0039 0.0088]\n",
      "Sum of all weights (should be 1.0): 1.0\n",
      "\n",
      "Per-tree metric summary (head):\n",
      "        acc      prec    rec        f1  composite    weight\n",
      "0  0.529412  0.500000  0.375  0.428571   1.832983  0.002700\n",
      "1  0.823529  1.000000  0.625  0.769231   3.217760  0.010784\n",
      "2  0.647059  0.666667  0.500  0.571429   2.385154  0.004690\n",
      "3  0.529412  0.500000  0.625  0.555556   2.209967  0.003936\n",
      "4  0.764706  0.750000  0.750  0.750000   3.014706  0.008802\n",
      "\n",
      "=== Softmax-Weighted Random Forest ===\n",
      "Accuracy: 0.6111111111111112\n",
      "Log-loss: 0.6327873860093123\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59         9\n",
      "           1       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.61      0.61      0.61        18\n",
      "weighted avg       0.61      0.61      0.61        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, classification_report, log_loss\n",
    ")\n",
    "from scipy.special import softmax\n",
    "\n",
    "TEST_SIZE = 0.20       # 20% test\n",
    "VAL_SIZE = 0.25        # 25% of (train+val) used as val\n",
    "N_ESTIMATORS = 200\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Composite metric weights: [accuracy, precision, recall, f1]\n",
    "COMPOSITE_WEIGHTS = np.array([1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "# Softmax temperature \n",
    "TEMPERATURE = 1.0\n",
    "\n",
    "\n",
    "# 1. Train / Val / Test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=VAL_SIZE, random_state=RANDOM_STATE, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# 2. Train standard Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=N_ESTIMATORS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Standard RF predictions (equal-weight voting)\n",
    "proba_std = rf.predict_proba(X_test)\n",
    "y_pred_std = np.argmax(proba_std, axis=1)\n",
    "logloss_std = log_loss(y_test, proba_std)\n",
    "\n",
    "print(\"\\n=== Standard Random Forest ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_std))\n",
    "print(\"Log-loss:\", logloss_std)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_std))\n",
    "\n",
    "# 3. Compute per-tree metrics on validation set\n",
    "tree_metrics = []   # rows: [acc, prec, rec, f1] per tree\n",
    "\n",
    "for tree in rf.estimators_:\n",
    "    val_pred = tree.predict(X_val)\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    prec = precision_score(y_val, val_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, val_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, val_pred, zero_division=0)\n",
    "    tree_metrics.append([acc, prec, rec, f1])\n",
    "\n",
    "tree_metrics = np.array(tree_metrics)  # shape: (n_trees, 4)\n",
    "\n",
    "# Composite score = weighted sum of [acc, prec, rec, f1]\n",
    "composite_scores = tree_metrics.dot(COMPOSITE_WEIGHTS)\n",
    "\n",
    "# Softmax over trees -> normalized weights that sum to 1\n",
    "weights = softmax(composite_scores / TEMPERATURE)\n",
    "\n",
    "print(\"\\nFirst 5 composite scores:\", np.round(composite_scores[:5], 4))\n",
    "print(\"First 5 weights:\", np.round(weights[:5], 4))\n",
    "print(\"Sum of all weights (should be 1.0):\", weights.sum())\n",
    "\n",
    "# view tree metrics + weights\n",
    "tree_summary = pd.DataFrame(\n",
    "    tree_metrics,\n",
    "    columns=[\"acc\", \"prec\", \"rec\", \"f1\"]\n",
    ")\n",
    "tree_summary[\"composite\"] = composite_scores\n",
    "tree_summary[\"weight\"] = weights\n",
    "print(\"\\nPer-tree metric summary (head):\")\n",
    "print(tree_summary.head())\n",
    "\n",
    "# 4. Softmax-weighted ensemble on test set\n",
    "# Start with zeros, then add each tree's probabilities scaled by its weight\n",
    "proba_weighted = np.zeros_like(proba_std)\n",
    "\n",
    "for w, tree in zip(weights, rf.estimators_):\n",
    "    proba_weighted += w * tree.predict_proba(X_test)\n",
    "\n",
    "y_pred_weighted = np.argmax(proba_weighted, axis=1)\n",
    "logloss_weighted = log_loss(y_test, proba_weighted)\n",
    "\n",
    "print(\"\\n=== Softmax-Weighted Random Forest ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_weighted))\n",
    "print(\"Log-loss:\", logloss_weighted)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3842032a-9092-43e7-8f74-2d8d4642f5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_matrix shape: (200, 4)\n",
      "example row: [0.52941176 0.5        0.375      0.42857143]\n"
     ]
    }
   ],
   "source": [
    "# Rebuilding metrics_matrix, val_proba_per_tree, test_proba_per_tree\n",
    "\n",
    "metrics_matrix = []            # Will become shape (n_trees, 4)\n",
    "val_proba_per_tree = []        # list of arrays\n",
    "test_proba_per_tree = []       # list of arrays\n",
    "\n",
    "for tree in rf.estimators_:\n",
    "    # Per-tree predictions on validation set\n",
    "    val_pred = tree.predict(X_val.values)\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    prec = precision_score(y_val, val_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, val_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, val_pred, zero_division=0)\n",
    "    metrics_matrix.append([acc, prec, rec, f1])\n",
    "\n",
    "    # Per-tree probabilities on val and test sets\n",
    "    val_proba_per_tree.append(tree.predict_proba(X_val.values))\n",
    "    test_proba_per_tree.append(tree.predict_proba(X_test.values))\n",
    "\n",
    "metrics_matrix = np.array(metrics_matrix)\n",
    "\n",
    "print(\"metrics_matrix shape:\", metrics_matrix.shape)\n",
    "print(\"example row:\", metrics_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0eca78c-2c79-4526-a204-ac7158ca5460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_matrix shape: (200, 4)\n",
      "first row of metrics_matrix: [0.52941176 0.5        0.375      0.42857143]\n",
      "temperature set to: 1.0\n"
     ]
    }
   ],
   "source": [
    "# REQUIRED SETUP BEFORE WEIGHT TUNING\n",
    "\n",
    "temperature = 1.0   # Default softmax temperature is 1 for reference\n",
    "\n",
    "metrics_matrix = []\n",
    "val_proba_per_tree = []\n",
    "test_proba_per_tree = []\n",
    "\n",
    "for tree in rf.estimators_:\n",
    "    # Per tree validation predictions\n",
    "    val_pred = tree.predict(X_val.values)\n",
    "    acc = accuracy_score(y_val, val_pred)\n",
    "    prec = precision_score(y_val, val_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, val_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, val_pred, zero_division=0)\n",
    "    metrics_matrix.append([acc, prec, rec, f1])\n",
    "\n",
    "    # Per tree probabilities on val/test\n",
    "    val_proba_per_tree.append(tree.predict_proba(X_val.values))\n",
    "    test_proba_per_tree.append(tree.predict_proba(X_test.values))\n",
    "\n",
    "metrics_matrix = np.array(metrics_matrix)\n",
    "\n",
    "print(\"metrics_matrix shape:\", metrics_matrix.shape)\n",
    "print(\"first row of metrics_matrix:\", metrics_matrix[0])\n",
    "print(\"temperature set to:\", temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d398b3-0382-4fc3-86d8-a4d1b987cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 256 weight combinations...\n",
      "\n",
      "Best weight vector [acc, prec, rec, f1]: (2.0, 2.0, 2.0, 2.0)\n",
      "Best validation log-loss: 0.3971\n",
      "Best validation accuracy: 0.8824\n",
      "\n",
      "=== Softmax RF with TUNED weights (Test set) ===\n",
      "Test accuracy: 0.5556\n",
      "Test log-loss: 0.6647\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.56      0.56      0.56        18\n",
      "weighted avg       0.56      0.56      0.56        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss, classification_report\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Pre compute per tree probabilities on val and test sets\n",
    "val_proba_per_tree = [tree.predict_proba(X_val.values) for tree in rf.estimators_]\n",
    "test_proba_per_tree = [tree.predict_proba(X_test.values) for tree in rf.estimators_]\n",
    "\n",
    "def evaluate_weight_vector(weight_vec, metrics_matrix,\n",
    "                           val_proba_per_tree, y_val, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Given a 4-dim weight vector [w_acc, w_prec, w_rec, w_f1],\n",
    "    compute composite scores -> softmax tree weights -> validation performance.\n",
    "    Returns (val_logloss, val_accuracy, tree_weights).\n",
    "    \"\"\"\n",
    "    weight_vec = np.array(weight_vec, dtype=float)\n",
    "    # Per tree composite score\n",
    "    composite_scores = metrics_matrix @ weight_vec\n",
    "    # Softmax to get non-negative weights that sum to 1\n",
    "    tree_weights = softmax(composite_scores / temperature)\n",
    "\n",
    "    # Aggregate weighted probabilities on validation set\n",
    "    proba_val = np.zeros_like(val_proba_per_tree[0])\n",
    "    for tw, p in zip(tree_weights, val_proba_per_tree):\n",
    "        proba_val += tw * p\n",
    "\n",
    "    val_logloss = log_loss(y_val, proba_val)\n",
    "    val_acc = accuracy_score(y_val, np.argmax(proba_val, axis=1))\n",
    "    return val_logloss, val_acc, tree_weights\n",
    "\n",
    "# Define a small grid of candidate weights\n",
    "candidate_vals = [0.0, 0.5, 1.0, 2.0]  # you can tweak/expand this later\n",
    "weight_grid = list(itertools.product(candidate_vals, repeat=4))\n",
    "print(f\"Evaluating {len(weight_grid)} weight combinations...\")\n",
    "\n",
    "best = {\n",
    "    \"w\": None,\n",
    "    \"val_logloss\": np.inf,\n",
    "    \"val_acc\": 0.0\n",
    "}\n",
    "\n",
    "for w in weight_grid:\n",
    "    ll, acc, _ = evaluate_weight_vector(\n",
    "        w, metrics_matrix, val_proba_per_tree, y_val, temperature=temperature\n",
    "    )\n",
    "    if ll < best[\"val_logloss\"]:\n",
    "        best[\"w\"] = w\n",
    "        best[\"val_logloss\"] = ll\n",
    "        best[\"val_acc\"] = acc\n",
    "\n",
    "print(\"\\nBest weight vector [acc, prec, rec, f1]:\", best[\"w\"])\n",
    "print(f\"Best validation log-loss: {best['val_logloss']:.4f}\")\n",
    "print(f\"Best validation accuracy: {best['val_acc']:.4f}\")\n",
    "\n",
    "# Use best weights to evaluate on TEST set\n",
    "best_w = np.array(best[\"w\"], dtype=float)\n",
    "best_composite_scores = metrics_matrix @ best_w\n",
    "best_tree_weights = softmax(best_composite_scores / temperature)\n",
    "\n",
    "# Aggregate weighted probabilities on test set\n",
    "proba_test = np.zeros_like(test_proba_per_tree[0])\n",
    "for tw, p in zip(best_tree_weights, test_proba_per_tree):\n",
    "    proba_test += tw * p\n",
    "\n",
    "test_logloss = log_loss(y_test, proba_test)\n",
    "y_pred_test = np.argmax(proba_test, axis=1)\n",
    "\n",
    "print(\"\\n=== Softmax RF with TUNED weights (Test set) ===\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Test log-loss: {test_logloss:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "331cf90b-b99b-400b-a644-dad65a3199dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported as school_funding_performance_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned dataset with funding performance metadata\n",
    "final_clean.to_csv(\"school_funding_performance_clean.csv\", index=False)\n",
    "print(\"Exported as school_funding_performance_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44cae3e3-099f-4248-9d7a-f80f704806ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: school_usable_columns.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDSCODE</th>\n",
       "      <th>MPD_NAME</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MPD_TYPE</th>\n",
       "      <th>MAP_TYPE</th>\n",
       "      <th>CHARTER</th>\n",
       "      <th>LD</th>\n",
       "      <th>Campus</th>\n",
       "      <th>Budget (incl c/o) FY24</th>\n",
       "      <th>Expenditures FY24</th>\n",
       "      <th>% Exp FY24</th>\n",
       "      <th>Pct_Met_Above</th>\n",
       "      <th>Mean_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19647336057939</td>\n",
       "      <td>NIMITZ MS</td>\n",
       "      <td>90255</td>\n",
       "      <td>J</td>\n",
       "      <td>MS</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NIMITZ MS</td>\n",
       "      <td>18802827.0</td>\n",
       "      <td>16689938.43</td>\n",
       "      <td>0.887629</td>\n",
       "      <td>34.657500</td>\n",
       "      <td>2499.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19647336061394</td>\n",
       "      <td>AUDUBON MS</td>\n",
       "      <td>90008</td>\n",
       "      <td>J</td>\n",
       "      <td>MS</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>AUDUBON MS</td>\n",
       "      <td>12618220.0</td>\n",
       "      <td>10690015.33</td>\n",
       "      <td>0.847189</td>\n",
       "      <td>27.157500</td>\n",
       "      <td>2473.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19647331931054</td>\n",
       "      <td>WESTSIDE GLBL AWR MAG</td>\n",
       "      <td>90292</td>\n",
       "      <td>SP</td>\n",
       "      <td>M</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>WESTSIDE GLBL AWR MAG</td>\n",
       "      <td>5263785.0</td>\n",
       "      <td>4628859.74</td>\n",
       "      <td>0.879379</td>\n",
       "      <td>45.118571</td>\n",
       "      <td>2482.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19647336107064</td>\n",
       "      <td>PIO PICO MS</td>\n",
       "      <td>90019</td>\n",
       "      <td>J</td>\n",
       "      <td>MS</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>PIO PICO MS</td>\n",
       "      <td>6573638.0</td>\n",
       "      <td>4915339.49</td>\n",
       "      <td>0.747735</td>\n",
       "      <td>36.482500</td>\n",
       "      <td>2503.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19647336057889</td>\n",
       "      <td>BELVEDERE MS</td>\n",
       "      <td>90063</td>\n",
       "      <td>J</td>\n",
       "      <td>MS</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>BELVEDERE MS</td>\n",
       "      <td>13920639.0</td>\n",
       "      <td>11795271.36</td>\n",
       "      <td>0.847323</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>2491.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CDSCODE               MPD_NAME    ZIP MPD_TYPE MAP_TYPE CHARTER LD  \\\n",
       "0  19647336057939              NIMITZ MS  90255        J       MS          0   \n",
       "1  19647336061394             AUDUBON MS  90008        J       MS          0   \n",
       "2  19647331931054  WESTSIDE GLBL AWR MAG  90292       SP        M          0   \n",
       "3  19647336107064            PIO PICO MS  90019        J       MS          0   \n",
       "4  19647336057889           BELVEDERE MS  90063        J       MS          0   \n",
       "\n",
       "                  Campus  Budget (incl c/o) FY24  Expenditures FY24  \\\n",
       "0              NIMITZ MS              18802827.0        16689938.43   \n",
       "1             AUDUBON MS              12618220.0        10690015.33   \n",
       "2  WESTSIDE GLBL AWR MAG               5263785.0         4628859.74   \n",
       "3            PIO PICO MS               6573638.0         4915339.49   \n",
       "4           BELVEDERE MS              13920639.0        11795271.36   \n",
       "\n",
       "   % Exp FY24  Pct_Met_Above   Mean_Score  \n",
       "0    0.887629      34.657500  2499.500000  \n",
       "1    0.847189      27.157500  2473.133333  \n",
       "2    0.879379      45.118571  2482.016667  \n",
       "3    0.747735      36.482500  2503.633333  \n",
       "4    0.847323      30.900000  2491.900000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the usable columns (assumed best fit by looking)\n",
    "usable_columns = [\n",
    "    \"CDSCODE\",\n",
    "    \"MPD_NAME\",\n",
    "    \"ZIP\",\n",
    "    \"MPD_TYPE\",\n",
    "    \"MAP_TYPE\",\n",
    "    \"CHARTER\",\n",
    "    \"LD\",\n",
    "    \"Campus\",\n",
    "    \"Budget (incl c/o) FY24\",\n",
    "    \"Expenditures FY24\",\n",
    "    \"% Exp FY24\",\n",
    "    \"Pct_Met_Above\",\n",
    "    \"Mean_Score\"\n",
    "]\n",
    "\n",
    "if \"Performance_Level\" in final_clean.columns:\n",
    "    usable_columns.append(\"Performance_Level\")\n",
    "\n",
    "usable_df = final_clean[usable_columns]\n",
    "\n",
    "# Export to CSV\n",
    "usable_df.to_csv(\"school_usable_columns.csv\", index=False)\n",
    "print(\"Exported: school_usable_columns.csv\")\n",
    "\n",
    "usable_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e481640-55d3-456c-917a-94fd9aa6c1db",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "070717f8-0e7d-4f30-b89b-e8e6c4705a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Recreate the same train/test split for fairness\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale X\n",
    "scaler_svm = StandardScaler()\n",
    "X_train_svm_scaled = scaler_svm.fit_transform(X_train_svm)\n",
    "X_test_svm_scaled = scaler_svm.transform(X_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b71ffeb-c6db-4d91-8c57-3cb803643757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;, probability=True, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', probability=True, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "# probability = True enables predict_proba\n",
    "svm_linear = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "\n",
    "svm_linear.fit(X_train_svm_scaled, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea2a757b-0b6a-4700-8fbc-6aa1bd299764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.5909090909090909\n",
      "Linear SVM Log-loss: 0.7150278022862803\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        11\n",
      "           1       0.55      1.00      0.71        11\n",
      "\n",
      "    accuracy                           0.59        22\n",
      "   macro avg       0.78      0.59      0.51        22\n",
      "weighted avg       0.78      0.59      0.51        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict class labels\n",
    "y_pred_svm = svm_linear.predict(X_test_svm_scaled)\n",
    "\n",
    "# Predict probabilities for log loss\n",
    "proba_svm = svm_linear.predict_proba(X_test_svm_scaled)\n",
    "\n",
    "print(\"Linear SVM Accuracy:\", accuracy_score(y_test_svm, y_pred_svm))\n",
    "print(\"Linear SVM Log-loss:\", log_loss(y_test_svm, proba_svm))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99a2d09b-198c-4800-8f93-457a177abc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>% Exp FY24</td>\n",
       "      <td>0.328171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Campus_KNOLLWOOD PREP ACAD</td>\n",
       "      <td>0.173528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Campus_ROYBAL LC</td>\n",
       "      <td>0.134023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Campus_TORRES RENAISSANCE</td>\n",
       "      <td>0.120487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Campus_BRADLEY GLBL AWR MAG</td>\n",
       "      <td>0.092264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Campus_PIO PICO MS</td>\n",
       "      <td>0.087914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAP_TYPE_MS</td>\n",
       "      <td>0.080211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Campus_REED MS</td>\n",
       "      <td>0.079131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Campus_MULHOLLAND MS</td>\n",
       "      <td>0.077844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Campus_BURROUGHS MS</td>\n",
       "      <td>0.075301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Campus_FOSHAY LC</td>\n",
       "      <td>0.072835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Campus_TORRES HUM/ART/TECH</td>\n",
       "      <td>0.072065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Campus_MARK TWAIN MS</td>\n",
       "      <td>0.069837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MPD_TYPE_ES</td>\n",
       "      <td>0.065764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MPD_TYPE_EP</td>\n",
       "      <td>0.065098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Feature  Coefficient\n",
       "2                    % Exp FY24     0.328171\n",
       "56   Campus_KNOLLWOOD PREP ACAD     0.173528\n",
       "85             Campus_ROYBAL LC     0.134023\n",
       "96    Campus_TORRES RENAISSANCE     0.120487\n",
       "28  Campus_BRADLEY GLBL AWR MAG     0.092264\n",
       "79           Campus_PIO PICO MS     0.087914\n",
       "18                  MAP_TYPE_MS     0.080211\n",
       "81               Campus_REED MS     0.079131\n",
       "71         Campus_MULHOLLAND MS     0.077844\n",
       "29          Campus_BURROUGHS MS     0.075301\n",
       "46             Campus_FOSHAY LC     0.072835\n",
       "95   Campus_TORRES HUM/ART/TECH     0.072065\n",
       "65         Campus_MARK TWAIN MS     0.069837\n",
       "8                   MPD_TYPE_ES     0.065764\n",
       "7                   MPD_TYPE_EP     0.065098"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Coefficient\": svm_linear.coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "coef_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa0423-1bcd-4e8a-a105-2ca6751fd88e",
   "metadata": {},
   "source": [
    "trying non linear svm because reults are asymetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8b03e85-db82-40d4-b7ab-5dd6e8a8816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM Accuracy: 0.7272727272727273\n",
      "RBF SVM Log-loss: 0.7933964480537927\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67        11\n",
      "           1       0.67      0.91      0.77        11\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.76      0.73      0.72        22\n",
      "weighted avg       0.76      0.73      0.72        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "# Same scaled data as linear SVM\n",
    "svm_rbf = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=True, random_state=42)\n",
    "\n",
    "svm_rbf.fit(X_train_svm_scaled, y_train_svm)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rbf = svm_rbf.predict(X_test_svm_scaled)\n",
    "proba_rbf = svm_rbf.predict_proba(X_test_svm_scaled)\n",
    "\n",
    "print(\"RBF SVM Accuracy:\", accuracy_score(y_test_svm, y_pred_rbf))\n",
    "print(\"RBF SVM Log-loss:\", log_loss(y_test_svm, proba_rbf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7051784f-6486-46df-8679-0318f601c0c2",
   "metadata": {},
   "source": [
    "much better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4160f70-4b39-4335-996a-59afe0259ea9",
   "metadata": {},
   "source": [
    "Testing Naive Bayes (Gaussian) next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12a40b84-2cdb-46e5-9543-9d4fb4a6731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5\n",
      "Naive Bayes Log-loss: 5.670793403278697\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.50      1.00      0.67        11\n",
      "\n",
      "    accuracy                           0.50        22\n",
      "   macro avg       0.25      0.50      0.33        22\n",
      "weighted avg       0.25      0.50      0.33        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2956: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_svm_scaled, y_train_svm)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test_svm_scaled)\n",
    "proba_nb = nb.predict_proba(X_test_svm_scaled)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test_svm, y_pred_nb))\n",
    "print(\"Naive Bayes Log-loss:\", log_loss(y_test_svm, proba_nb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb307af-77e9-46b0-9277-16e087be2089",
   "metadata": {},
   "source": [
    "not worth trying to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f046529-5390-4011-9352-18db8d5f67cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Accuracy: 0.6818181818181818\n",
      "kNN Log-loss: 3.72911292776203\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63        11\n",
      "           1       0.64      0.82      0.72        11\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.70      0.68      0.68        22\n",
      "weighted avg       0.70      0.68      0.68        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\codyl\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\codyl\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\codyl\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\codyl\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "# Trying k = 3 neighbors because of smaller dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn.fit(X_train_svm_scaled, y_train_svm)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_svm_scaled)\n",
    "proba_knn = knn.predict_proba(X_test_svm_scaled)\n",
    "\n",
    "print(\"kNN Accuracy:\", accuracy_score(y_test_svm, y_pred_knn))\n",
    "print(\"kNN Log-loss:\", log_loss(y_test_svm, proba_knn))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_knn))\n",
    "\n",
    "# note from after running... wow that logloss is high lol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e5c4d-06e4-4b45-b045-bbafa90a4a6d",
   "metadata": {},
   "source": [
    "Gradient Boosting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b332cf2-ade4-4a79-be9a-4dd8cd812a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.6818181818181818\n",
      "Gradient Boosting Log-loss: 0.7236162451469907\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        11\n",
      "           1       0.67      0.73      0.70        11\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.68      0.68      0.68        22\n",
      "weighted avg       0.68      0.68      0.68        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "# Gradient Boosting works fine on scaled or unscaled data\n",
    "# reuse the same scaled features you used for SVM\n",
    "# X_train_svm_scaled, X_test_svm_scaled, y_train_svm, y_test_svm\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=100,   \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=3         \n",
    ")\n",
    "\n",
    "gb.fit(X_train_svm_scaled, y_train_svm)\n",
    "\n",
    "y_pred_gb = gb.predict(X_test_svm_scaled)\n",
    "proba_gb = gb.predict_proba(X_test_svm_scaled)\n",
    "\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test_svm, y_pred_gb))\n",
    "print(\"Gradient Boosting Log-loss:\", log_loss(y_test_svm, proba_gb))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_svm, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e38a16-1768-415f-8141-55f0c925143c",
   "metadata": {},
   "source": [
    "one last check just to see if restrictions can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f5c6edd-4705-4306-a111-4921b02cd7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = final_clean[[\n",
    "    \"ZIP\",\n",
    "    \"Budget (incl c/o) FY24\",\n",
    "    \"Expenditures FY24\",\n",
    "    \"% Exp FY24\"\n",
    "]].copy()\n",
    "\n",
    "y_reduced = y.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66edb89d-7683-4d9f-8ecb-fb252784eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(\n",
    "    X_reduced, y_reduced, test_size=0.25, random_state=42, stratify=y_reduced\n",
    ")\n",
    "\n",
    "scaler_red = StandardScaler()\n",
    "X_train_red_s = scaler_red.fit_transform(X_train_red)\n",
    "X_test_red_s = scaler_red.transform(X_test_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0a493f9-fc50-443c-806c-1b6d992cb67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM (Reduced Features) Accuracy: 0.6363636363636364\n",
      "RBF SVM (Reduced) Log-loss: 0.6127530940852953\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67        11\n",
      "           1       0.67      0.55      0.60        11\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.64      0.64      0.63        22\n",
      "weighted avg       0.64      0.64      0.63        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "\n",
    "svm_rbf_red = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", probability=True, random_state=42)\n",
    "svm_rbf_red.fit(X_train_red_s, y_train_red)\n",
    "\n",
    "y_pred_rbf_red = svm_rbf_red.predict(X_test_red_s)\n",
    "proba_rbf_red = svm_rbf_red.predict_proba(X_test_red_s)\n",
    "\n",
    "print(\"RBF SVM (Reduced Features) Accuracy:\", accuracy_score(y_test_red, y_pred_rbf_red))\n",
    "print(\"RBF SVM (Reduced) Log-loss:\", log_loss(y_test_red, proba_rbf_red))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_red, y_pred_rbf_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "344296a6-f6ef-48b2-900c-632f34a19f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final restricted dataset shape: (86, 4) (86,)\n",
      "Train: (54, 4), Val: (14, 4), Test: (18, 4)\n",
      "\n",
      "=== Standard Random Forest (Restricted Features) ===\n",
      "Accuracy: 0.6111111111111112\n",
      "Log-loss: 0.6530559742267938\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59         9\n",
      "           1       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.61      0.61      0.61        18\n",
      "weighted avg       0.61      0.61      0.61        18\n",
      "\n",
      "\n",
      "Per-tree metrics matrix shape: (100, 4)\n",
      "\n",
      "Evaluating 256 weight combinations...\n",
      "\n",
      "Best weight vector [acc, prec, rec, f1]: (3.0, 3.0, 3.0, 3.0)\n",
      "Best validation log-loss: 0.3327\n",
      "Best validation accuracy: 0.8571\n",
      "\n",
      "=== Softmax RF with TUNED weights (Restricted Features, Test set) ===\n",
      "Test Accuracy: 0.5555555555555556\n",
      "Test Log-loss: 0.8240223372995491\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.56      0.56      0.56         9\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.56      0.56      0.56        18\n",
      "weighted avg       0.56      0.56      0.56        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, log_loss,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Set up data \n",
    "# Use your cleaned modeling dataset\n",
    "model_df = final_clean.copy()\n",
    "\n",
    "# Restricted feature set based on importance graph\n",
    "feature_cols = [\n",
    "    \"ZIP\",\n",
    "    \"Budget (incl c/o) FY24\",\n",
    "    \"Expenditures FY24\",\n",
    "    \"% Exp FY24\"\n",
    "]\n",
    "\n",
    "# Target variable \n",
    "threshold = model_df[\"Pct_Met_Above\"].median()\n",
    "y = (model_df[\"Pct_Met_Above\"] >= threshold).astype(int).values\n",
    "\n",
    "# Select features\n",
    "X = model_df[feature_cols].copy()\n",
    "\n",
    "# Ensure all are numeric\n",
    "for col in feature_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "\n",
    "# Drop rows with any missing values\n",
    "valid_mask = X.notna().all(axis=1)\n",
    "X = X[valid_mask]\n",
    "y = y[valid_mask.values]\n",
    "\n",
    "# Convert X to NumPy array\n",
    "X = X.values\n",
    "\n",
    "print(\"Final restricted dataset shape:\", X.shape, y.shape)\n",
    "\n",
    "# 2. Train/Val/Test split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.20, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Train a standard Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=None\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Standard RF predictions\n",
    "proba_std = rf.predict_proba(X_test)\n",
    "y_pred_std = np.argmax(proba_std, axis=1)\n",
    "log_std = log_loss(y_test, proba_std)\n",
    "\n",
    "print(\"\\n=== Standard Random Forest (Restricted Features) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_std))\n",
    "print(\"Log-loss:\", log_std)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_std))\n",
    "\n",
    "\n",
    "# Compute per-tree validation metrics\n",
    "tree_metrics = []\n",
    "val_proba_per_tree = []\n",
    "test_proba_per_tree = []\n",
    "\n",
    "for tree in rf.estimators_:\n",
    "    preds_val = tree.predict(X_val)\n",
    "\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    prec = precision_score(y_val, preds_val, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_val, preds_val, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val, preds_val, average='weighted', zero_division=0)\n",
    "\n",
    "    tree_metrics.append([acc, prec, rec, f1])\n",
    "\n",
    "    val_proba_per_tree.append(tree.predict_proba(X_val))\n",
    "    test_proba_per_tree.append(tree.predict_proba(X_test))\n",
    "\n",
    "metrics_matrix = np.array(tree_metrics)\n",
    "val_proba_per_tree = np.array(val_proba_per_tree)\n",
    "test_proba_per_tree = np.array(test_proba_per_tree)\n",
    "\n",
    "print(\"\\nPer-tree metrics matrix shape:\", metrics_matrix.shape)\n",
    "\n",
    "# Helper function: evaluate weight vector on validation set\n",
    "def evaluate_weight_vector(w, metrics_matrix, val_proba_per_tree, y_val, temperature=1.0):\n",
    "    w = np.array(w, dtype=float)\n",
    "    composite_scores = metrics_matrix.dot(w)\n",
    "    tree_weights = softmax(composite_scores / temperature)\n",
    "\n",
    "    # Weighted probabilities for validation set\n",
    "    val_proba_weighted = np.tensordot(tree_weights, val_proba_per_tree, axes=(0, 0))\n",
    "    \n",
    "    val_ll = log_loss(y_val, val_proba_weighted)\n",
    "    val_pred = np.argmax(val_proba_weighted, axis=1)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    \n",
    "    return val_ll, val_acc, tree_weights\n",
    "\n",
    "# Grid search over weight combinations\n",
    "temperature = 1.0\n",
    "candidate_vals = [0.0, 1.0, 2.0, 3.0]\n",
    "weight_grid = list(product(candidate_vals, repeat=4))  # 4^4 = 256 combos\n",
    "\n",
    "best = {\n",
    "    \"w\": None,\n",
    "    \"val_logloss\": np.inf,\n",
    "    \"val_acc\": 0.0,\n",
    "    \"weights_per_tree\": None\n",
    "}\n",
    "\n",
    "print(f\"\\nEvaluating {len(weight_grid)} weight combinations...\")\n",
    "\n",
    "for w in weight_grid:\n",
    "    ll, acc, tw = evaluate_weight_vector(\n",
    "        w, metrics_matrix, val_proba_per_tree, y_val, temperature\n",
    "    )\n",
    "\n",
    "    if ll < best[\"val_logloss\"]:\n",
    "        best[\"w\"] = w\n",
    "        best[\"val_logloss\"] = ll\n",
    "        best[\"val_acc\"] = acc\n",
    "        best[\"weights_per_tree\"] = tw\n",
    "\n",
    "print(\"\\nBest weight vector [acc, prec, rec, f1]:\", best[\"w\"])\n",
    "print(\"Best validation log-loss:\", round(best[\"val_logloss\"], 4))\n",
    "print(\"Best validation accuracy:\", round(best[\"val_acc\"], 4))\n",
    "\n",
    "# Evaluate tuned Softmax RF on the TEST set\n",
    "best_tree_weights = best[\"weights_per_tree\"]\n",
    "\n",
    "# Weighted probabilities for test set\n",
    "test_proba_weighted = np.tensordot(best_tree_weights, test_proba_per_tree, axes=(0, 0))\n",
    "test_logloss = log_loss(y_test, test_proba_weighted)\n",
    "y_test_pred = np.argmax(test_proba_weighted, axis=1)\n",
    "\n",
    "print(\"\\n=== Softmax RF with TUNED weights (Restricted Features, Test set) ===\")\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Test Log-loss:\", test_logloss)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
